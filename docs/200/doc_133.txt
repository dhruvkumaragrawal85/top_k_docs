scriptstyle f(x) </math> , whereas in statistical modeling , it could be related to the posterior probability of the model given the data . ( Note that in both of those examples those quantities would be maximized rather than minimized ) . Tasks that fall within the paradigm of unsupervised learning are in general estimation problems ; the applications include clustering , the estimation of statistical distributions , compression and filtering . # #Reinforcement learning# # @ @ @ @ @ @ @ @ @ @ usually not given , but generated by an agent 's interactions with the environment . At each point in time <math> scriptstyle t </math> , the agent performs an action <math> scriptstyle yt </math> and the environment generates an observation <math> scriptstyle xt </math> and an instantaneous cost <math> scriptstyle ct </math> , according to some ( usually unknown ) dynamics . The aim is to discover a ' ' policy ' ' for selecting actions that minimizes some measure of a long-term cost ; i.e. , the expected cumulative cost . The environment 's dynamics and the long-term cost for each policy are usually unknown , but can be estimated . More formally the environment is modelled as a Markov decision process ( MDP ) with states <math> scriptstyle s1 , ... , snin S </math> and actions <math> scriptstyle a1 , ... , am in A </math> with the following probability distributions : the instantaneous cost distribution <math> scriptstyle P(ctst) </math> , the observation distribution <math> scriptstyle P(xtst) </math> and the transition <math> scriptstyle P ( st+1st , at ) </math> , while a policy is defined as conditional @ @ @ @ @ @ @ @ @ @ the two then define a Markov chain ( MC ) . The aim